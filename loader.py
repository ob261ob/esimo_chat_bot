import os
import requests
from dotenv import load_dotenv
from langchain_community.graphs import Neo4jGraph
import streamlit as st
from streamlit.logger import get_logger
from datetime import datetime
import json
import streamlit as st
load_dotenv(".env")
from chains import (
    load_embedding_model,
    load_llm
)
from utils import (
    create_constraints,
    create_vector_index,
    BaseLogger,
)
url = os.getenv("NEO4J_URI")
username = os.getenv("NEO4J_USERNAME")
password = os.getenv("NEO4J_PASSWORD")
ollama_base_url = os.getenv("OLLAMA_BASE_URL")
embedding_model_name = os.getenv("EMBEDDING_MODEL")
llm_name = os.getenv("LLM") or "llama3"
# Remapping for Langchain Neo4j integration
os.environ["NEO4J_URL"] = url

logger = get_logger(__name__)


embeddings, dimension = load_embedding_model(
    embedding_model_name, config={"ollama_base_url": ollama_base_url}, logger=logger
)

# if Neo4j is local, you can go to http://localhost:7474/ to browse the database
neo4j_graph = Neo4jGraph(url=url, username=username, password=password)

create_constraints(neo4j_graph)
create_vector_index(neo4j_graph, dimension)

llm = load_llm(
    llm_name, logger=BaseLogger(), config={"ollama_base_url": ollama_base_url}
)
def generate_region(description: str) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–≥–∏–æ–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø–∏—Å–∞–Ω–∏—è —Å–æ–±—ã—Ç–∏—è —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω–æ–π Ollama"""
    
    prompt = f"""
    –û–ø—Ä–µ–¥–µ–ª–∏, –≤ –∫–∞–∫–æ–º —Ä–µ–≥–∏–æ–Ω–µ –†–æ—Å—Å–∏–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —ç—Ç–æ —Å–æ–±—ã—Ç–∏–µ, –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø–∏—Å–∞–Ω–∏—è.
    –û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Ä–µ–≥–∏–æ–Ω–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ú–æ—Å–∫–≤–∞", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", 
    "–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä—Å–∫–∏–π –∫—Ä–∞–π"). –ú–æ–∂–µ—à—å —Ç–∞–∫ –∂–µ –ø–∏—Å–∞—Ç—å –Ω–∑–∞–≤–∞–Ω–∏–µ –º–æ—Ä—è, —Ñ–µ–¥–µ–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–≥–∞ –∏–ª–∏ –æ–∫–µ–∞–Ω–∞. –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ—à—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –≤–µ—Ä–Ω–∏ "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ".
    
    –û–ø–∏—Å–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è: {description}
    –†–µ–≥–∏–æ–Ω:
    """
    
    try:
        region = llm.invoke(prompt)
        return region.content.strip()  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏ –∏ –ø—Ä–æ–±–µ–ª—ã
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–≥–∏–æ–Ω–∞: {e}")
        return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    
# def load_so_data(tag: str = "neo4j", page: int = 1) -> None:
#     parameters = (
#         f"?pagesize=100&page={page}&order=desc&sort=creation&answers=1&tagged={tag}"
#         "&site=stackoverflow&filter=!*236eb_eL9rai)MOSNZ-6D3Q6ZKb0buI*IVotWaTb"
#     )
#     data = requests.get(so_api_base_url + parameters).json()
#     insert_so_data(data)


# def load_high_score_so_data() -> None:
#     parameters = (
#         f"?fromdate=1664150400&order=desc&sort=votes&site=stackoverflow&"
#         "filter=!.DK56VBPooplF.)bWW5iOX32Fh1lcCkw1b_Y6Zkb7YD8.ZMhrR5.FRRsR6Z1uK8*Z5wPaONvyII"
#     )
#     data = requests.get(so_api_base_url + parameters).json()
#     insert_so_data(data)


# def insert_so_data(data: dict) -> None:
#     # Calculate embedding values for questions and answers
#     for q in data["items"]:
#         question_text = q["title"] + "\n" + q["body_markdown"]
#         q["embedding"] = embeddings.embed_query(question_text)
#         for a in q["answers"]:
#             a["embedding"] = embeddings.embed_query(
#                 question_text + "\n" + a["body_markdown"]
#             )

#     # Cypher, the query language of Neo4j, is used to import the data
#     # https://neo4j.com/docs/getting-started/cypher-intro/
#     # https://neo4j.com/docs/cypher-cheat-sheet/5/auradb-enterprise/
#     import_query = """
#     UNWIND $data AS q
#     MERGE (question:Question {id:q.question_id}) 
#     ON CREATE SET question.title = q.title, question.link = q.link, question.score = q.score,
#         question.favorite_count = q.favorite_count, question.creation_date = datetime({epochSeconds: q.creation_date}),
#         question.body = q.body_markdown, question.embedding = q.embedding
#     FOREACH (tagName IN q.tags | 
#         MERGE (tag:Tag {name:tagName}) 
#         MERGE (question)-[:TAGGED]->(tag)
#     )
#     FOREACH (a IN q.answers |
#         MERGE (question)<-[:ANSWERS]-(answer:Answer {id:a.answer_id})
#         SET answer.is_accepted = a.is_accepted,
#             answer.score = a.score,
#             answer.creation_date = datetime({epochSeconds:a.creation_date}),
#             answer.body = a.body_markdown,
#             answer.embedding = a.embedding
#         MERGE (answerer:User {id:coalesce(a.owner.user_id, "deleted")}) 
#         ON CREATE SET answerer.display_name = a.owner.display_name,
#                       answerer.reputation= a.owner.reputation
#         MERGE (answer)<-[:PROVIDED]-(answerer)
#     )
#     WITH * WHERE NOT q.owner.user_id IS NULL
#     MERGE (owner:User {id:q.owner.user_id})
#     ON CREATE SET owner.display_name = q.owner.display_name,
#                   owner.reputation = q.owner.reputation
#     MERGE (owner)-[:ASKED]->(question)
#     """
#     neo4j_graph.query(import_query, {"data": data["items"]})

def insert_so_data(data: list) -> None:
    if not isinstance(data, list):
        raise ValueError("–û–∂–∏–¥–∞–µ—Ç—Å—è —Å–ø–∏—Å–æ–∫ –¥–∞–Ω–Ω—ã—Ö.")

    if len(data) == 0:
        st.warning("–°–ø–∏—Å–æ–∫ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç.")
        return

    progress_bar = st.progress(0, text="–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

    processed_data = []
    for idx, item in enumerate(data):
        if not isinstance(item, dict):
            raise ValueError("–ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç –¥–∞–Ω–Ω—ã—Ö –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º.")
        
        required_keys = ["id", "title", "link", "start_date", "end_date", "description", "region", "embedding"]
        for key in required_keys:
            if key not in item:
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á: {key} –≤ —ç–ª–µ–º–µ–Ω—Ç–µ –¥–∞–Ω–Ω—ã—Ö {item}")

        # –û–±–Ω–æ–≤–ª—è–µ–º embedding –∑–∞–Ω–æ–≤–æ
        item["embedding"] = embeddings.embed_query(item["title"])

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–≥–∏–æ–Ω–∞
        raw_region = item.get("region", "")
        clean_region = raw_region.strip("[]")
        region_list = [r.strip() for r in clean_region.split(",") if r.strip()]
        item["region_list"] = region_list

        processed_data.append(item)

        # üîΩ –ü–æ–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è
        st.markdown(f"‚û°Ô∏è –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è: **{item['title']}**")

        progress = int((idx + 1) / len(data) * 50)
        progress_bar.progress(progress, text=f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞: {progress}%")

    # –¶–∏–∫–ª –∏–º–ø–æ—Ä—Ç–∞ –≤ Neo4j
    import_query = """
    UNWIND $data AS item
    MERGE (data:Data {id: item.id})
    ON CREATE SET 
        data.title = item.title, 
        data.link = item.link, 
        data.start_date = datetime({epochSeconds: item.start_date}), 
        data.end_date = datetime({epochSeconds: item.end_date}), 
        data.description = item.description, 
        data.embedding = item.embedding
    WITH data, item.region_list AS regions
    UNWIND regions AS region_name
    MERGE (region:Region {name: region_name})
    MERGE (data)-[:LOCATED_IN]->(region)
    """

    batch_size = 10
    for i in range(0, len(processed_data), batch_size):
        batch = processed_data[i:i+batch_size]
        neo4j_graph.query(import_query, {"data": batch})
        progress = 50 + int((i + batch_size) / len(processed_data) * 50)
        progress_bar.progress(min(progress, 100), text=f"–ò–º–ø–æ—Ä—Ç: {min(progress, 100)}%")

    progress_bar.progress(100, text="–ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à—ë–Ω ‚úÖ")





# Streamlit
def get_tag() -> str:
    input_text = st.text_input(
        "Which tag questions do you want to import?", value="neo4j"
    )
    return input_text


def get_pages():
    col1, col2 = st.columns(2)
    with col1:
        num_pages = st.number_input(
            "Number of pages (100 questions per page)", step=1, min_value=1
        )
    with col2:
        start_page = st.number_input("Start page", step=1, min_value=1)
    st.caption("Only questions with answers will be imported.")
    return (int(num_pages), int(start_page))


# def render_page():
#     datamodel_image = Image.open("./images/datamodel.png")
#     st.header("StackOverflow Loader")
#     st.subheader("Choose StackOverflow tags to load into Neo4j")
#     st.caption("Go to http://localhost:7474/ to explore the graph.")

#     user_input = get_tag()
#     num_pages, start_page = get_pages()

#     if st.button("Import", type="primary"):
#         with st.spinner("Loading... This might take a minute or two."):
#             try:
#                 for page in range(1, num_pages + 1):
#                     load_so_data(user_input, start_page + (page - 1))
#                 st.success("Import successful", icon="‚úÖ")
#                 st.caption("Data model")
#                 st.image(datamodel_image)
#                 st.caption("Go to http://localhost:7474/ to interact with the database")
#             except Exception as e:
#                 st.error(f"Error: {e}", icon="üö®")
#     with st.expander("Highly ranked questions rather than tags?"):
#         if st.button("Import highly ranked questions"):
#             with st.spinner("Loading... This might take a minute or two."):
#                 try:
#                     load_high_score_so_data()
#                     st.success("Import successful", icon="‚úÖ")
#                 except Exception as e:
#                     st.error(f"Error: {e}", icon="üö®")



def render_page():
    st.header("ESIMO Data Loader ‚Äî –í–≤–æ–¥ —Å–æ–±—ã—Ç–∏–π –≤—Ä—É—á–Ω—É—é")

    if "events" not in st.session_state:
        st.session_state["events"] = []

    st.subheader("–î–æ–±–∞–≤—å—Ç–µ –Ω–æ–≤–æ–µ —Å–æ–±—ã—Ç–∏–µ")
    with st.form(key=f"form_add_event_{len(st.session_state['events'])}"):

        event_id = st.text_input("ID –°–æ–±—ã—Ç–∏—è", key="event_id")
        title = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ", key="title")
        link = st.text_input("–°—Å—ã–ª–∫–∞", key="link")
        start_date = st.text_input("–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ (–≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD)", key="start_date")
        end_date = st.text_input("–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è (–≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD)", key="end_date")
        description = st.text_area("–û–ø–∏—Å–∞–Ω–∏–µ", key="description")
        region = st.text_input("–†–µ–≥–∏–æ–Ω", key="region")

        submit_event = st.form_submit_button(label="–î–æ–±–∞–≤–∏—Ç—å —Å–æ–±—ã—Ç–∏–µ")
        embedding = embeddings.embed_query(title)
        if submit_event:
            st.session_state["events"].append({
                "id": event_id,
                "title": title,
                "link": link,
                "start_date": start_date,
                "end_date": end_date,
                "description": description,
                "region": region,
                "embedding": embedding
            })
            st.success("–°–æ–±—ã—Ç–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞.", icon="‚úÖ")

    st.subheader("–°–ø–∏—Å–æ–∫ —Å–æ–±—ã—Ç–∏–π –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞")
    if st.session_state["events"]:
        for idx, event in enumerate(st.session_state["events"]):
            with st.expander(f"–°–æ–±—ã—Ç–∏–µ {idx + 1}: {event['title']}"):
                st.write("ID:", event["id"])
                st.write("–ù–∞–∑–≤–∞–Ω–∏–µ:", event["title"])
                st.write("–°—Å—ã–ª–∫–∞:", event["link"])
                st.write("–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞:", event["start_date"])
                st.write("–î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è:", event["end_date"])
                st.write("–û–ø–∏—Å–∞–Ω–∏–µ:", event["description"])
                st.write("–†–µ–≥–∏–æ–Ω:", event["region"])

    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞ JSON
    st.subheader("–í—ã–≥—Ä—É–∑–∏—Ç—å —Å–æ–±—ã—Ç–∏—è –∏–∑ —Ñ–∞–π–ª–∞ JSON")
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª JSON", type=["json"])

    if uploaded_file:
        try:
            file_data = json.load(uploaded_file)
            progress_bar = st.progress(0)
            total = len(file_data)

            for idx, event_data in enumerate(file_data):
                # embedding = embeddings.embed_query(event_data["title"])  # –ó–∞–ø–æ–ª–Ω—è–µ–º embedding
                embedding = ""
                st.session_state["events"].append({
                    "id": event_data.get("identifier", ""),
                    "title": event_data["title"],
                    "link": event_data["link"],
                    "start_date": int(datetime.strptime(event_data["start_date"].split("T")[0], "%Y-%m-%d").timestamp()),
                    "end_date": int(datetime.strptime(event_data["end_date"].split("T")[0], "%Y-%m-%d").timestamp()),
                    "description": event_data["description"],
                    "region": event_data.get("geographic_coverage", {}).get("geo_object_name", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
                    "embedding": embedding
                })
                progress_bar.progress((idx + 1) / total)

            progress_bar.empty()
            st.success("–°–æ–±—ã—Ç–∏—è —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞!", icon="‚úÖ")
        except json.JSONDecodeError:
            st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.")
        except Exception as e:
            st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")


    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π
    if st.button("–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —Å–æ–±—ã—Ç–∏—è"):
        if st.session_state["events"]:
            data = st.session_state["events"]
            with st.spinner("–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö..."):
                try:
                    insert_so_data(data)
                    st.success("–í—Å–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã!", icon="‚úÖ")
                    st.session_state["events"] = []  # –û—á–∏—â–∞–µ–º –ø–æ—Å–ª–µ –∏–º–ø–æ—Ä—Ç–∞
                except Exception as e:
                    st.error(f"–ü–µ—Ä–µ–¥–µ–ª—ã–≤–∞–π: {e}")
        else:
            st.error("–ù–µ—Ç —Å–æ–±—ã—Ç–∏–π –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞.")

# –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏
render_page()
